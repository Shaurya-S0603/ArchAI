{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "private_outputs": true,
      "collapsed_sections": [
        "Iyql1szfIpxd"
      ],
      "mount_file_id": "1NfjmX-nb4GszvWmmGuyPpESpYTHFRBVQ",
      "authorship_tag": "ABX9TyNkOYJJ32S0/J0/iW2QRmgB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shaurya-S0603/ArchAI/blob/main/ArchAI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TRAINING AND TESTING**"
      ],
      "metadata": {
        "id": "Iyql1szfIpxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import gc\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import DatasetFolder\n",
        "from PIL import Image\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# ✅ Enable expandable segments for better memory allocation\n",
        "%env PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True\n",
        "\n",
        "# ✅ Enable CuDNN Benchmarking for speed boost\n",
        "torch.backends.cudnn.benchmark = True\n",
        "\n",
        "# ✅ Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Using device: {device}\")\n",
        "\n",
        "# ✅ Training Parameters\n",
        "BATCH_SIZE = 4  # Increased batch size for efficiency\n",
        "IMG_SIZE = 64\n",
        "LATENT_DIM = 100\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.0002\n",
        "ACCUM_STEPS = 2  # Gradient accumulation steps\n",
        "\n",
        "# ✅ Dataset and Transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "class ImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, root, transform):\n",
        "        self.images = [os.path.join(root, f) for f in os.listdir(root) if f.endswith(('.png', '.jpg', '.jpeg'))]\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = Image.open(self.images[idx]).convert(\"RGB\")\n",
        "        return self.transform(image), 0  # No labels\n",
        "\n",
        "dataset = ImageDataset(\"/content/drive/MyDrive/ArchAI_Dataset/train\", transform)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "# ✅ Define Generator\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.init_size = IMG_SIZE // 4  # Reduce spatial resolution to scale up properly\n",
        "        self.l1 = nn.Sequential(nn.Linear(LATENT_DIM, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "# ✅ Define Discriminator\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, stride=2, padding=1),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * (IMG_SIZE // 4) * (IMG_SIZE // 4), 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.model(img)\n",
        "\n",
        "# ✅ Initialize Models with `torch.compile()` for speed boost\n",
        "generator = torch.compile(Generator().to(device))\n",
        "discriminator = torch.compile(Discriminator().to(device))\n",
        "\n",
        "# ✅ Define loss and optimizers\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=LEARNING_RATE, betas=(0.5, 0.999))\n",
        "scaler = torch.amp.GradScaler(\"cuda\")\n",
        "\n",
        "# ✅ Training Loop with Gradient Accumulation\n",
        "def train_gan(epochs=EPOCHS):\n",
        "    for epoch in range(epochs):\n",
        "        for i, (real_images, _) in enumerate(dataloader):\n",
        "            real_images = real_images.to(device)\n",
        "            batch_size = real_images.size(0)\n",
        "            real_labels = torch.ones(batch_size, 1).to(device)\n",
        "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
        "\n",
        "            # ✅ Train Generator with gradient accumulation\n",
        "            optimizer_G.zero_grad()\n",
        "            z = torch.randn(batch_size, LATENT_DIM).to(device)\n",
        "            with torch.amp.autocast(\"cuda\"):\n",
        "                fake_images = generator(z)\n",
        "                fake_output = discriminator(fake_images)\n",
        "                loss_G = criterion(fake_output, real_labels) / ACCUM_STEPS\n",
        "            scaler.scale(loss_G).backward()\n",
        "            if (i + 1) % ACCUM_STEPS == 0:\n",
        "                scaler.step(optimizer_G)\n",
        "                scaler.update()\n",
        "                optimizer_G.zero_grad()\n",
        "\n",
        "            # ✅ Train Discriminator\n",
        "            optimizer_D.zero_grad()\n",
        "            with torch.amp.autocast(\"cuda\"):\n",
        "                real_output = discriminator(real_images)\n",
        "                loss_real = criterion(real_output, real_labels)\n",
        "                fake_output = discriminator(fake_images.detach())\n",
        "                loss_fake = criterion(fake_output, fake_labels)\n",
        "                loss_D = (loss_real + loss_fake) / (2 * ACCUM_STEPS)\n",
        "            scaler.scale(loss_D).backward()\n",
        "            if (i + 1) % ACCUM_STEPS == 0:\n",
        "                scaler.step(optimizer_D)\n",
        "                scaler.update()\n",
        "                optimizer_D.zero_grad()\n",
        "\n",
        "            # ✅ Free memory\n",
        "            del real_images, fake_images, fake_output, real_output, loss_G, loss_D, loss_real, loss_fake, z\n",
        "            torch.cuda.empty_cache()\n",
        "            gc.collect()\n",
        "\n",
        "            # ✅ Reduce print frequency\n",
        "            if i % 500 == 0:\n",
        "                print(f\"Epoch [{epoch}/{epochs}] | Batch [{i}/{len(dataloader)}] | Loss D: {loss_D.item():.4f}, Loss G: {loss_G.item():.4f}\")\n",
        "\n",
        "        # ✅ Save Model Every 10 Epochs\n",
        "        if epoch % 10 == 0:\n",
        "            torch.save(generator.state_dict(), f\"/content/drive/MyDrive/ArchAI/models/generator_epoch_{epoch}.pth\")\n",
        "            torch.save(discriminator.state_dict(), f\"/content/drive/MyDrive/ArchAI/models/discriminator_epoch_{epoch}.pth\")\n",
        "            print(f\"✅ Checkpoint saved at epoch {epoch}\")\n",
        "\n",
        "# ✅ Train the model\n",
        "train_gan(epochs=EPOCHS)\n",
        "\n",
        "# ✅ Save Final Model\n",
        "torch.save(generator.state_dict(), \"/content/drive/MyDrive/ArchAI/models/generator_final.pth\")\n",
        "torch.save(discriminator.state_dict(), \"/content/drive/MyDrive/ArchAI/models/discriminator_final.pth\")\n",
        "print(\"✅ Final models saved!\")"
      ],
      "metadata": {
        "id": "NEpgHMei60nm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# ✅ Check for GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"✅ Using device: {device}\")\n",
        "\n",
        "# ✅ Generation Parameters\n",
        "LATENT_DIM = 100\n",
        "IMG_SIZE = 64\n",
        "\n",
        "# ✅ Define Generator\n",
        "class Generator(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        self.init_size = IMG_SIZE // 4\n",
        "        self.l1 = torch.nn.Sequential(torch.nn.Linear(LATENT_DIM, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = torch.nn.Sequential(\n",
        "            torch.nn.BatchNorm2d(128),\n",
        "            torch.nn.Upsample(scale_factor=2),\n",
        "            torch.nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(128, 0.8),\n",
        "            torch.nn.LeakyReLU(0.2),\n",
        "            torch.nn.Upsample(scale_factor=2),\n",
        "            torch.nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            torch.nn.BatchNorm2d(64, 0.8),\n",
        "            torch.nn.LeakyReLU(0.2),\n",
        "            torch.nn.Conv2d(64, 3, 3, stride=1, padding=1),\n",
        "            torch.nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img\n",
        "\n",
        "# ✅ Load Trained Generator\n",
        "generator = Generator().to(device)\n",
        "generator.load_state_dict(torch.load(\"/content/drive/MyDrive/ArchAI/models/generator.pth\", map_location=device))\n",
        "generator.eval()\n",
        "\n",
        "# ✅ Generate and Display Images\n",
        "def generate_images(num_images=5):\n",
        "    z = torch.randn(num_images, LATENT_DIM).to(device)\n",
        "    with torch.no_grad():\n",
        "        fake_images = generator(z).cpu()\n",
        "\n",
        "    fake_images = (fake_images + 1) / 2  # Normalize to [0,1]\n",
        "\n",
        "    fig, axes = plt.subplots(1, num_images, figsize=(15, 15))\n",
        "    for i in range(num_images):\n",
        "        img = transforms.ToPILImage()(fake_images[i])\n",
        "        axes[i].imshow(img)\n",
        "        axes[i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# ✅ Generate and Show Images\n",
        "generate_images()\n"
      ],
      "metadata": {
        "id": "hufxSZHxGaVS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}